# yaml-language-server: $schema=schema.yaml
title: "Header: ``<lmno/lex.hpp>``"
intro: |
  .. namespace:: lmno::lex

  The |lmno| tokenization API can be used to split a string into |lmno| tokens and
  inspect those tokens. The `token` type is used throughout the codebase to refer
  to names entities.

  All entities within this subsection are defined within the :cpp:`lmno::lex`
  namespace.
ns: lmno::lex
contents:
  Classes and Class Templates:
    - name: token
      desc: A string-like type that stores the contents of an |lmno| token
      ent-page:
        kind: struct
        name: token
        intro: |
          A single token, represented as a string. Valid as a non-type template
          parameter. Fully :cpp:`constexpr`. The contained string is immutable.

          The token owns its string contents, but does not allocate. Each token
          contains a `char` array with a maximum size of `max_token_length`.
        contents:
          Constructors:
            - name: token
              desc: Construct a new token
              ent-page:
                kind: ctor
                name: token
                sigs:
                  - sig: constexpr token() noexcept = default
                    desc: |
                      Default-construct an empty :class:`token`.
                      The token will have a `size()` of `0`.
                  - sig: constexpr token(const char* s) noexcept
                    desc: |
                      Construct a :class:`token` that copies charactes from a
                      null-terminated array of `char` that begins at `s`.
                      The pointed-to array must have fewer than `max_token_length`
                      `char`\ s

          Accessors:
            - name: data
              desc: Get a pointer to the token's string
              ent-page:
                name: data
                kind: fn
                sigs: [data() const noexcept -> const char*]
                intro: |
                  Get the pointer to the beginning of the underlying
                  `char` array.

                  .. note:: Never returns `nullptr`

            - name: size
              desc: Get the size of the token string
              page:
                title: "``token::size``"
                intro: ".. namespace:: lmno::lex::token"
                entities:
                  - kind: fn
                    sigs: [size() const noexcept -> std::size_t]
                    intro: |
                      Get the size of the token (in UTF-8 code units)

            - name: operator[]
              desc: Get the Nth code-unit of the token string
              ent-page:
                name: operator[]
                kind: fn
                sigs:
                  - operator[](std::size_t n) const noexcept -> char
                intro: |
                  Access the `n`\ th `char` within the token string.

            - name: operator std::string_view
              desc: Access the token as a `std::string_view`
              ent-page:
                name: operator std::string_view
                kind: fn
                sigs:
                  - operator std::string_view() const noexcept
                intro: |
                  Implicit conversion to `std::string_view`

          Associated Constants:
            - name: max_token_length
              desc: The maximum length of a token
              ent-page:
                kind: const
                ns: "lmno::lex"
                type: constexpr std::size_t
                name: max_token_length
                intro: |
                  The maximum number of UTF-8 code units that can be placed
                  in a `token`.
    - name: token_list
      desc: An incomplete class template that encodes a sequence of `token`\ s
      ent-page:
        kind: class
        name: token_list
        template: <token... Tokens>
        main: |
          A type representing the value of a list of `token`\ s.

          .. note::

            This template has no definition, so it cannot be instantiated
            (only specialized).

          .. seealso::

            A `token_list` is generated by passing a string to `tokenize_t`.

  Alias Templates:
    - name: tokenize_t
      desc: Generate a `token_list` for the given ``cx_str`` string
      ent-page:
        kind: type
        name: tokenize_t
        template: <cx_str String>
        is: token_list<__deduced_t>
        intro: |
          Generate a `token_list` from the given |lmno| ``cx_str`` string, tokenized according to
          the |lmno| grammar::

            static_assert(
              std::same_as<
                tokenize_t<R"(
                  foo (bar
                    baz     (: This is a comment :)
                  )   quux
                )">,
                token_list<token{"foo"},
                          token{"("},
                          token{"bar"},
                          token{"baz"},
                          token{")"},
                          token{"quux"}>
              >
            );

  Functions:
    - name: is_digit, is_alpha, is_ident
      slug: classify
      desc: "`char` Classifier functions"
      page:
        title: "`char` Classifier Functions"
        ns: lmno::lex

        entities:
          - kind: fn
            intro: |
              The functions `is_digit`, `is_alpha`, and `is_ident` are used to classify values
              of `char` according to the |lmno| grammar.
            sigs:
              - sig: is_digit(char c) -> bool
                desc: Return `true` if `c` is an **ASCII digit**.
              - sig: is_alpha(char c) -> bool
                desc: Return `true` if `c` is an **ASCII alphabetic** letter.
              - sig: is_ident(char c) -> bool
                desc: Return `true` if `c` is an **ASCII digit**,
                  an **ASCII alphabetic** letter, or an **underscore**.
