The Parser
##########

.. default-role:: cpp
.. highlight:: cpp
.. cpp:namespace:: lmno

This page details the implementation of the |lmno| parser. It accepts, as input,
a :class:`~lmno::lex::token_list` type (which was probably generated by :doc:`tokenizer`).

Of all the components in |lmno|, this one saw the most complete rewrites, as I
kept finding better and better ways to do it.


The Naive Approach
******************

Suppose you are given a :class:`lmno::lex::token_list` type. If we want to write
a parser over the tokens, one's first instinct might be to write a parser based
on pattern matching with class-template partial specialization, or pattern
matching based on function overloading. This approach works and is very easy to
understand, especially as the parser has a close resemblance to the input
grammar, but it suffers from a huge drawback:

.. centered:: It is *incredbily slow* to compile.

This was the first iteration of the |lmno| parser. The trouble comes from the
enormous number of class templates that that need to be generated, or the
repeated application of overload resolution.

For small programs, this a small cost. For *many* small programs, things start
to become expensive. For many *moderate* sized programs, the cost is inhibiting.
For *large* programs, this approach is untennable.


Constexpr Recursive Descent?
============================

Maybe a hand-written recursive descent parser would be good? Something like
this:

.. code-block:: cpp

  template <token Head, token... Tail>
  constexpr auto parse_primary(token_list<Head, Tail...>*, auto acc) {
    if constexpr (Head == "(") {
      constexpr auto [inner, remainder] = parse_expr(ptr<token_list<Tail...>>{}, acc);
      return parse_paren_finish(remainder, inner);
    } else if constexpr (is_number(Head)) {
      // Do something …
    } else if constexpr (/* … */) {
      // Do more stuff …
    } // etc…
  }

This approach also works, and is often faster! But…

.. centered:: This is still *incredbily slow*

The problem is again in template specialization: We are instantiating several
function templates *per token*. Additionally, certain `constexpr` evaluators get
tripped up by this recursion and compile times will *explode*.


The |lmno| Parser
*****************

The |lmno| parser is implemented in two phases. The second phase is a template
metaprogram pushdown automaton that constructs the AST from a set of simple
instructions. The first phase is a simple `constexpr` recursive descent
parser that fills a `std::array` with the intsructions that will build the
resulting tree.


Pushdown Instructions
*********************

A pushdown instruction looks like this::

  struct node {
    // What does this node do?
    ikind kind;
    // Operand value
    uint64_t n;
  };

The meaning of the `n` member depends on the `kind` value. `ikind` is a simple
`enum` that encodes a few instruction types.


Setup
=====

Firstly, we have our tokens encoded in a type, but we want them in an array that
we can iterate over as a regular array. This is actually an easy one-liner:

.. code-block::
  :emphasize-lines: 3

  template <token... Token>
  auto parse(token_list<Tokens...>*) {
    constexpr std::array<token, sizeof...(Tokens) + 1> token_arr = {Tokens...};
    // …
  }

With the `constexpr` `token_arr`, we can use it as a template parameter
to the next layer::

  template <auto TokenArray>
  constexpr auto make_parser() {
    // Make room for the program:
    std::array<node, Arr.size() * 2> ret = {};
    // The input:
    token_iter iter{TokenArray.data()};
    // The output:
    auto into = ret.data();
    // Do the parse!
    parse_top(into, iter);
    // Finish it off:
    *into = {ikind::k_done, 0};
    // Done.
    return ret;
  }

As with :doc:`tokenizer`, we use an additional level of indirection to create a
`constexpr` array of `node` that we return to the caller. The
`token_iter` type is a simple iterator-ish thing that allows us to keep track
of where we are in the token sequence while we also have access to those tokens.
`parse_top` is the function that parses an top-level expression (an
:token:`expr_seq`).


Parsing Recursively
===================

All of the parser functions have the same signature::

  constexpr void parse_something(node*& into, token_iter& it);

that is, they take the input and output pointers by reference. A more complex
parser that required backtracking and error recovery would likely not use
mutable references in this manner. Since our parser is very simple, this will do
just fine.


Example: Parsing Sequence Expressions
-------------------------------------

As an example, the top-level expression parser looks like this::

  constexpr void parse_seq(node*& into, token_iter& it) {
    uint64_t n_exprs = 0;
    while (1) {
      parse_assign(into, it);
      ++n_exprs;
      if (it.get() != ";") {
        break;
      }
      it.pos++;
    }
    if (n_exprs > 1) {
      *into++ = {ikind::k_seq, n_exprs};
    }
  }

It works simply:

1. Set $N_{exprs}$ to $0$.
2. Parse an assignment-expression (:token:`expr_assign`).
3. Increment $N_{exprs}$ by $1$
4. If the current token is now as ASCII semicolon "`;`", go to step 7.
5. Advance the token iterator by one position
6. Go to step 2.
7. If $N_{exprs} > 1$, append a new instruction of type `k_seq` ("generate a
   sequence-expression") with an operand of $N_{exprs}$ ("the number of
   expressions that are part of the sequence").

Each parser function follows similar procedures: Inspect the current token,
write pushdown instructions, advance the current token, or return, in some
order.


Example: Parsing Primary Expressions
------------------------------------

At the bottom of the parser is the primary-expression parser. It is surprisingly
simple::

  constexpr static auto parse_primary(node*& into, token_iter& it) {
    const auto tk = std::string_view(it.get());
    const char c  = tk.front();
    if (is_ascii_alpha(c)) {
      *into++ = {ikind::k_name, it.pos};
      it.pos++;
    } else if (is_ascii_digit(c) or tk.starts_with("¯")) {
      *into++ = {ikind::k_int, it.pos};
      it.pos++;
    } else if (c == '(') {
      it.pos++;
      parse_top(into, it);
      if (it.get()[0] != ')') {
        throw "Imbalanced parentheses";
      }
      it.pos++;
    } else if (c == '{') {
      it.pos++;
      parse_top(into, it);
      *into++ = {ikind::k_block, 0};
      if (it.get()[0] != '}') {
        throw "Imbalanced braces";
      }
      it.pos++;
    } else if (tk == "·") {
      *into++ = {ikind::k_nothing, 0};
      it.pos++;
    } else {
      *into++ = {ikind::k_name, it.pos};
      it.pos++;
    }
  }

The only "complex" cases here are recursing on opening parenthesis "`(`" and
opening brace "`{`", which just check for balance.


Building the Tree
*****************

Once we have an array of our "automoton intsructions", we can send them to the
exucutor that will actually build the tree.

One's first instinct will be to do more partial specialization:

.. code-block::
  :caption: *wrong*

  template <node Head, node... Tail, typename Stack>
  struct exec_more<list<k_seq, Tail...>, Stack> { /* … */ };

But remember why the prior parser was slow! Instantiating class templates is
*slow*!


Executing
=========

In the |lmno| parser, execution is handled by a multi-layer set of class
templates and alias templates that focus on instantiating as *few* unique
template specializations as possible. We start from the `parse()` function,
where we have our nodes array::

  auto parse(token_list<Tokens...>*) {
    // …
    constexpr auto nodes = make_parser<TokenArray>();
    using ast = executor<TokenArray>::template exec_parse_t<nodes>;
    return static_cast<ast*>(nullptr);
  }

The `executor` class template accepts the array of tokens as its sole template
parameter. We then "call" a member alias template `exec_parse_t`. It looks
like this::

  template <auto Tokens>
  struct executor {
    template <auto Nodes,
              uint64_t Idx = 0,
              typename Stack = list<>>
    using exec_parse_t =
        parse<Nodes[Idx].kind>
      ::template f<Nodes, Idx, Stack>;
  };

We use the default template arguments to "initialize" some "variables" that will
be used for the parse. `Idx` is the index within `Nodes` that we are
"executing", while `Stack` is the actual stack for the pushdown automaton,
which starts empty.


Looping
=======

The `parse` template is a member class template of the `executor` class
template. It looks like this::

  template <ikind K>
  struct parse {
    using CurStep = step<K>;
    template <auto Nodes,
              auto Idx,
              typename StackIn,
              typename StackOut =
                  CurStep::template f<Nodes[Idx].n, StackIn>
              >
    using f = exec_parse_t<Nodes, Idx + 1, StackOut>;
  };

The `parse` template utilizes a default template argument to again do more
"computing". The `Nodes`, `Idx`, and `StackIn` parameter all come from the
"caller", but `StackOut` is calculated by "invoking" the `step<K>::f`, where `K`
is the instruction at `Idx`.

`step<>` is *another* member class template of `execution`, and is fully
specialized for each `ikind`. Each `step` specialization provides a nested
member alias template `f` which accepts as input the instruction's arbitrary
`uint64_t` value and the current stack. `f` resolves to the transformed stack
after the step operation has been applied.

Once we have the transformed `StackOut`, we recursively invoke `exec_parse_t`
with the same nodes, the next index, and the stack after the value has been
transformed.


Transforming
============

To see an example transformation, here is the `step<>` specialization for
`k_seq`::

  template <>
  struct step<k_seq> {
    template <uint64_t Count,
              typename Stack,
              typename Split = split_at<Stack, Count>,
              typename Head  = head<Split>,
              typename Tail  = tail<Split>,
              typename Seq   = rebind<reverse<Head>, stmt_seq>>
    using f = push_front<Tail, Seq>;
  };

This alias template again uses default template arguments to implement the
a sequence of computations:

1. `Count` and `Stack` come from the "caller".

   1. `Count` comes from the `node::n` value that was set by the first phase of
      the parse, which used `n` to represent the number of semicolon-separated
      expressions.
   2. `Stack` is the current pushdown stack that we are operating on.

2. `Split` is `split_at<Stack, Count>`, where `split_at` is a metafunction that
   separates the list `Stack` into a pair of lists, with `Count` items in the
   first element, and the remaining items in the second.
3. `Head` is the first element of the split. In this case, these are the
   expressions that are being grouped into a sequence node.
4. `Tail` is the expressions that are left over.
5. `Seq` is the new node:

   1. The `reverse` is a metafunction that simply reverses a list. Because of
      the way we construct nodes, the nodes on the stack are in reverse order of
      their lexical order in the original program.
   2. `rebind<L, T>` is a metafunction that accepts a class template
      specialization `L<Ts...>` and a class template `T`, and resolves to
      `T<Ts...>`. In this case we are taking the template arguments of `Head`
      (which is a list of expressions AST nodes) and rebinding those arguments
      to `stmt_seq` (which is itself a variadic template of AST nodes).

6. Finally, `f` resolves to `push_front<Tail, Seq>`, which will insert the
   single item `Seq` (our new `stmt_seq`) on the front of `Tail` (the remaining
   stack after we removed `Count` elements). This is the new transformed stack.


Stopping
========

Parsing "finishes" when `exec_parse_t` "invokes" `parse<k_done>::f`, as `parse`
is specialized for `k_done`::

   template <>
    struct parse<k_done> {
        // Final state: Return the one node:
        template <auto, auto, tn Stack>
        using f = head<Stack>;
    };

This stops the loop and returns the final type, which (for a well-formed parse)
will be a single AST node representing the entire program.
